{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0142b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import json\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb529d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def child_asin_count(url,sku):\n",
    "    \n",
    "    link='https://www.amazon.'+url+'/dp/'+sku\n",
    "    print('crawling',link)\n",
    "    headers = {\n",
    "        \"scheme\": \"https\",\n",
    "        \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "        \"accept-encoding\": \"gzip, deflate, br\",\n",
    "        \"accept-language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "        \"sec-fetch-dest\": \"document\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\"}\n",
    "    #headers = {\"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\"}\n",
    "    data = requests.get(link, headers=headers)\n",
    "    try:\n",
    "        asins_info = re.findall('\"dimensionValuesDisplayData\"\\s*:\\s*({.*?})', data.text)\n",
    "\n",
    "        no_asins = 0\n",
    "        asin_list = []\n",
    "        for asins_json in asins_info:\n",
    "            asins_json = json.loads(asins_json)\n",
    "            for key, value in asins_json.items():\n",
    "                if key:\n",
    "                    no_asins += 1\n",
    "        print(no_asins)\n",
    "    except:\n",
    "        print('\\ncrawling failed for:',link)\n",
    "    \n",
    "    return no_asins\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51d2331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the SERP Job Keystone id:\n",
      "6413f7d44cf7bd7022574cab\n",
      "client_id:\n",
      "134\n",
      "MX\n",
      "Following are the crawl dates.\n",
      "   crawl_date\n",
      "0 2023-03-17\n",
      "1 2023-03-18\n",
      "2 2023-03-19\n",
      "3 2023-03-20\n",
      "4 2023-03-21\n",
      "5 2023-03-22\n",
      "6 2023-03-23\n",
      "Still working.\n",
      "WAIT...\n",
      "run next Cell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "id= input(\"Enter the SERP Job Keystone id:\\n\")# 6242907baeaf3c20971706f6\n",
    "#id=('638f14f0de567323966e8af5','639305d5de567323966f6fce')\n",
    "client_id= input('client_id:\\n')\n",
    "\n",
    "tablename='client_{0}.serp_data_{1}'.format(client_id,client_id)\n",
    "\n",
    "query=f\"\"\"\n",
    "select country\n",
    "from client_resource.client_master\n",
    "where id ='{client_id}'\n",
    "\"\"\"\n",
    "dd=pd.read_sql_query(query, conn[1])\n",
    "country_id=dd['country'][0]\n",
    "print(country_id)\n",
    "\n",
    "# getting the crwal dates for SERP Job\n",
    "query_smd = f\"\"\"\n",
    "select *\n",
    "from ready.serp_mongo_details\n",
    "where keystone_job_id= '{id}' \"\"\"\n",
    "\n",
    "data = pd.read_sql_query(query_smd, conn[1])\n",
    "data['crawl_date'] = pd.to_datetime(data['crawl_date'])\n",
    "print('Following are the crawl dates.\\n',data['crawl_date'].sort_values().reset_index().drop('index',axis=1))\n",
    "\n",
    "#start_date= input('Input starting date in format e.g. 2022-03-29\\n')\n",
    "#end_date=input('Input end date in format e.g. 2022-03-31\\n')\n",
    "print('Still working.\\nWAIT...')\n",
    "\n",
    "#making a list of pipeline ids for given keystone job\n",
    "#mask = (data['crawl_date'] > start_date) & (data['crawl_date'] <= end_date)\n",
    "pipe_list=tuple(data['pipeline_id'].tolist())\n",
    "\n",
    "print(\"run next Cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05057e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Date2023-03-17\n",
      "Ending Date2023-03-22\n"
     ]
    }
   ],
   "source": [
    "startingdate=input('starting Date')\n",
    "endingdate= input('Ending Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf8bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please insert Request Number: 382\n",
      "Please insert Channel Name: Super Walmart\n"
     ]
    }
   ],
   "source": [
    "Rno=input('Please insert Request Number: ')\n",
    "Channel=input('Please insert Channel Name: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abcb7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= data[(data['crawl_date'] >= startingdate) & (data['crawl_date'] <= endingdate)]\n",
    "pipe_list=tuple(data1['pipeline_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d443433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please insert the keywords in the excel sheet with name keystone_keyword.xlsx.\n",
      " Loacate the file in same as code.\n",
      " If Done Press 1\n",
      " if you want to search keywords from feature enter 2\n",
      ":2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keywords applied on Keystone SERP Job are= 111\n",
      "Data in ready--->serp_details  crawled for keywords= 93\n",
      "Missing keywords in SERP Details: {'sabritas mini pack', 'sabritas grandes', 'papas fritas limon', 'chips fuego', 'sabritas bbq', 'nachos', 'papas fritas miguelito', 'chips jalapeÃ±o', 'paketaxo', 'sabritas originales', 'chetos mix', 'sabritas flamin hot', 'generico sabritas mini', 'sabritas original', 'flaming hot', 'chetos', 'sabritas naturales', 'rancheritos'}\n",
      "Run Next Cell\n"
     ]
    }
   ],
   "source": [
    "#fetiching serp data from production table\n",
    "query = f\"\"\"\n",
    "select *\n",
    "from ready.serp_details smd join ready.serp_mongo_details m on m.serp_mongo_id=smd.serp_mongo_id\n",
    "where  smd.crawl_date between '{startingdate}' and '{endingdate}' and keystone_job_id = '{id}'\n",
    "\"\"\"\n",
    "serp_data = pd.read_sql_query(query, conn[1])\n",
    "key_list=tuple(serp_data['keyword'].unique())\n",
    "\n",
    "\n",
    "#getting list of keywords from excel which made manually by coping keys from keystone.\n",
    "ui=input('Please insert the keywords in the excel sheet with name keystone_keyword.xlsx.\\n Loacate the file in same as code.\\n If Done Press 1\\n if you want to search keywords from feature enter 2\\n:')\n",
    "if ui =='1':\n",
    "    keystone_key_df=pd.read_excel('keystone_keyword.xlsx')\n",
    "    keystone_key=keystone_key_df['keyword'].tolist()\n",
    "\n",
    "elif ui=='2':\n",
    "    \n",
    "    query = \"select * from entity.keyword_category where country_code='{}' and feature= '{}'\".format(country_id, Rno)\n",
    "    keystone_key_df=pd.read_sql_query(query, conn[1])\n",
    "    keystone_key=keystone_key_df['keyword'].tolist()\n",
    "    \n",
    "else:\n",
    "    print('Do it and come back.')\n",
    "print('\\nKeywords applied on Keystone SERP Job are=', len(keystone_key))\n",
    "print('Data in ready--->serp_details  crawled for keywords=', len(key_list))\n",
    "diff1=len(keystone_key)-len(key_list)\n",
    "if diff1!=0:\n",
    "    print(\"Missing keywords in SERP Details:\", (set(keystone_key).difference(key_list)))\n",
    "else:\n",
    "    print(\"Check 1:\\nAll keywords applied are present in SERP_Details\")\n",
    "    \n",
    "    \n",
    "print(\"Run Next Cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e104b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['takis mix',\n",
       " 'barcel chipotles',\n",
       " 'barcel chips',\n",
       " 'barcel surtido',\n",
       " 'barcel takis azules',\n",
       " 'bolsa de mini sabritas',\n",
       " 'caja de mini sabritas',\n",
       " 'caja de papas sabritas mini',\n",
       " 'caja de sabritas surtido mini',\n",
       " 'cazares frituras',\n",
       " 'generico sabritas mini',\n",
       " 'lays surtido de papas',\n",
       " 'pack de 30 piezas botanas surtidas sabritas',\n",
       " 'papas sabritas',\n",
       " 'papas sabritas crema y especias',\n",
       " 'papas sabritas sabrisurtido con 35pzas',\n",
       " 'papitas sabritas mini',\n",
       " 'paquete de sabritas mini surtido',\n",
       " 'rufless mix',\n",
       " 'sabritas',\n",
       " 'sabritas 240',\n",
       " 'sabritas 54 gr',\n",
       " 'sabritas 55',\n",
       " 'sabritas adobadas',\n",
       " 'sabritas amarillas',\n",
       " 'sabritas bbq',\n",
       " 'sabritas blancas',\n",
       " 'sabritas bolzaza',\n",
       " 'sabritas caja',\n",
       " 'sabritas crema y especias',\n",
       " 'sabritas crujientes moradas',\n",
       " 'sabritas de limon',\n",
       " 'sabritas de messi',\n",
       " 'sabritas especias',\n",
       " 'sabritas familiar',\n",
       " 'sabritas flamin',\n",
       " 'sabritas flamin hot',\n",
       " 'sabritas grandes',\n",
       " 'sabritas habaneras',\n",
       " 'sabritas habanero',\n",
       " 'sabritas individuales',\n",
       " 'sabritas jamon serrano',\n",
       " 'sabritas jumbo',\n",
       " 'sabritas limon',\n",
       " 'sabritas mexicanas',\n",
       " 'sabritas mini',\n",
       " 'sabritas mini pack',\n",
       " 'sabritas mini surtido',\n",
       " 'sabritas mini surtido 50',\n",
       " 'sabritas mix',\n",
       " 'sabritas moradas',\n",
       " 'sabritas naturales',\n",
       " 'sabritas original',\n",
       " 'sabritas original mini',\n",
       " 'sabritas originales',\n",
       " 'sabritas pack',\n",
       " 'sabritas recetas crujiente flamin hot',\n",
       " 'sabritas rosas',\n",
       " 'sabritas sal',\n",
       " 'sabritas stax',\n",
       " 'sabritas surtido',\n",
       " 'sabritas variedad',\n",
       " 'sabritas veggie',\n",
       " 'susalitas enchiladas',\n",
       " 'susalitas nachos',\n",
       " 'veggie chips',\n",
       " 'veggie empaque surtido',\n",
       " 'bolitas de queso',\n",
       " 'botana',\n",
       " 'botanas',\n",
       " 'botanas surtidas',\n",
       " 'cheetos americanos',\n",
       " 'cheetos colmillo',\n",
       " 'cheetos flaming hot',\n",
       " 'cheetos mexican street corn',\n",
       " 'chetos',\n",
       " 'chetos americanos',\n",
       " 'chetos flaming hot',\n",
       " 'chetos mix',\n",
       " 'chettos flaming hot',\n",
       " 'chettos flaming hot limon',\n",
       " 'chettos flaming hot usa',\n",
       " 'chip',\n",
       " 'chips fuego',\n",
       " 'chips jalapeÃ±o',\n",
       " 'chips mini',\n",
       " 'doritos diablo',\n",
       " 'doritos ranch',\n",
       " 'flaming hot',\n",
       " 'frituras',\n",
       " 'nachos',\n",
       " 'paketaxo',\n",
       " 'paketaxo morado',\n",
       " 'papas',\n",
       " 'papas fritas',\n",
       " 'papas fritas a granel',\n",
       " 'papas fritas bolsa',\n",
       " 'papas fritas botana',\n",
       " 'papas fritas botana vegano',\n",
       " 'papas fritas con aceite de aguacate',\n",
       " 'papas fritas con miguelito',\n",
       " 'papas fritas con sal de mar',\n",
       " 'papas fritas limon',\n",
       " 'papas fritas miguelito',\n",
       " 'papas fritas por kilo',\n",
       " 'papitas picantes',\n",
       " 'pringles crema y cebolla',\n",
       " 'pringles mix pack',\n",
       " 'pringles original',\n",
       " 'pringles queso',\n",
       " 'rancheritos']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keystone_key_lower=[x.lower() for x in keystone_key]\n",
    "keystone_key_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d34d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "keystone_key1= \"'\" +  (\"'\" + \"','\".join(name.replace(\"'\", r\"''\") for name in keystone_key) + \"'\") + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5250c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>type</th>\n",
       "      <th>brand</th>\n",
       "      <th>country_code</th>\n",
       "      <th>feature</th>\n",
       "      <th>sys_keyword_id</th>\n",
       "      <th>included_keywords</th>\n",
       "      <th>md5_hash</th>\n",
       "      <th>id</th>\n",
       "      <th>sys_kwd_ctg_id</th>\n",
       "      <th>sys_submitted_by</th>\n",
       "      <th>sys_last_updated_on</th>\n",
       "      <th>sys_brand_id</th>\n",
       "      <th>epoch_ms_id</th>\n",
       "      <th>translated_keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barcel chipotles</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>barcel</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943669</td>\n",
       "      <td>None</td>\n",
       "      <td>574214053f9eea3ccce6374bd744939d</td>\n",
       "      <td>435706</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barcel chips</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>barcel</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943670</td>\n",
       "      <td>None</td>\n",
       "      <td>d024bb4e3bf54467035b3c80de4a4a77</td>\n",
       "      <td>435707</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barcel surtido</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>barcel</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943671</td>\n",
       "      <td>None</td>\n",
       "      <td>b45e4befad0d3ce0f7faf5cc545119b4</td>\n",
       "      <td>435708</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barcel takis azules</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>barcel</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943672</td>\n",
       "      <td>None</td>\n",
       "      <td>05fded166dfbeab2a502ce3101e94c05</td>\n",
       "      <td>435709</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bolitas de queso</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>generic</td>\n",
       "      <td>generic</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12921301</td>\n",
       "      <td>None</td>\n",
       "      <td>1f04008aee067dd284640df36eb507ac</td>\n",
       "      <td>435710</td>\n",
       "      <td>2</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>susalitas enchiladas</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>susalitas</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943815</td>\n",
       "      <td>None</td>\n",
       "      <td>d200b5d6a9bb5b714eef2899a705f1cd</td>\n",
       "      <td>435812</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>susalitas nachos</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>susalitas</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943816</td>\n",
       "      <td>None</td>\n",
       "      <td>0ffa9382cec62b3891c99f0e542112b2</td>\n",
       "      <td>435813</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>takis mix</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>takis</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943817</td>\n",
       "      <td>None</td>\n",
       "      <td>3d40cc841cf546d38578eedfdcba3f18</td>\n",
       "      <td>435814</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>veggie chips</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>veggie</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>3809329</td>\n",
       "      <td>None</td>\n",
       "      <td>0bd13bcbeea0bd8042f6d9f42a54c486</td>\n",
       "      <td>435815</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>veggie empaque surtido</td>\n",
       "      <td>food &amp; beverages</td>\n",
       "      <td>corn_</td>\n",
       "      <td>branded</td>\n",
       "      <td>veggie</td>\n",
       "      <td>MX</td>\n",
       "      <td>382</td>\n",
       "      <td>12943818</td>\n",
       "      <td>None</td>\n",
       "      <td>7d79f4f776731dea5293518c24ec1b52</td>\n",
       "      <td>435816</td>\n",
       "      <td>3</td>\n",
       "      <td>Karan Kumar</td>\n",
       "      <td>2023-03-17 06:31:03.141866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679035e+09</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    keyword          category sub_category     type  \\\n",
       "0          barcel chipotles  food & beverages        corn_  branded   \n",
       "1              barcel chips  food & beverages        corn_  branded   \n",
       "2            barcel surtido  food & beverages        corn_  branded   \n",
       "3       barcel takis azules  food & beverages        corn_  branded   \n",
       "4          bolitas de queso  food & beverages        corn_  generic   \n",
       "..                      ...               ...          ...      ...   \n",
       "106    susalitas enchiladas  food & beverages        corn_  branded   \n",
       "107        susalitas nachos  food & beverages        corn_  branded   \n",
       "108               takis mix  food & beverages        corn_  branded   \n",
       "109            veggie chips  food & beverages        corn_  branded   \n",
       "110  veggie empaque surtido  food & beverages        corn_  branded   \n",
       "\n",
       "         brand country_code feature  sys_keyword_id included_keywords  \\\n",
       "0       barcel           MX     382        12943669              None   \n",
       "1       barcel           MX     382        12943670              None   \n",
       "2       barcel           MX     382        12943671              None   \n",
       "3       barcel           MX     382        12943672              None   \n",
       "4      generic           MX     382        12921301              None   \n",
       "..         ...          ...     ...             ...               ...   \n",
       "106  susalitas           MX     382        12943815              None   \n",
       "107  susalitas           MX     382        12943816              None   \n",
       "108      takis           MX     382        12943817              None   \n",
       "109     veggie           MX     382         3809329              None   \n",
       "110     veggie           MX     382        12943818              None   \n",
       "\n",
       "                             md5_hash      id  sys_kwd_ctg_id  \\\n",
       "0    574214053f9eea3ccce6374bd744939d  435706               3   \n",
       "1    d024bb4e3bf54467035b3c80de4a4a77  435707               3   \n",
       "2    b45e4befad0d3ce0f7faf5cc545119b4  435708               3   \n",
       "3    05fded166dfbeab2a502ce3101e94c05  435709               3   \n",
       "4    1f04008aee067dd284640df36eb507ac  435710               2   \n",
       "..                                ...     ...             ...   \n",
       "106  d200b5d6a9bb5b714eef2899a705f1cd  435812               3   \n",
       "107  0ffa9382cec62b3891c99f0e542112b2  435813               3   \n",
       "108  3d40cc841cf546d38578eedfdcba3f18  435814               3   \n",
       "109  0bd13bcbeea0bd8042f6d9f42a54c486  435815               3   \n",
       "110  7d79f4f776731dea5293518c24ec1b52  435816               3   \n",
       "\n",
       "    sys_submitted_by        sys_last_updated_on  sys_brand_id   epoch_ms_id  \\\n",
       "0        Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "1        Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "2        Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "3        Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "4        Karan Kumar 2023-03-17 06:31:03.141866         450.0  1.679035e+09   \n",
       "..               ...                        ...           ...           ...   \n",
       "106      Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "107      Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "108      Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "109      Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "110      Karan Kumar 2023-03-17 06:31:03.141866           NaN  1.679035e+09   \n",
       "\n",
       "    translated_keyword  \n",
       "0                 None  \n",
       "1                 None  \n",
       "2                 None  \n",
       "3                 None  \n",
       "4                 None  \n",
       "..                 ...  \n",
       "106               None  \n",
       "107               None  \n",
       "108               None  \n",
       "109               None  \n",
       "110               None  \n",
       "\n",
       "[111 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"select * from entity.keyword_category where country_code='{}' and keyword in ({}) and feature='{}'\".format(country_id,str(keystone_key1)[1:-1],Rno)\n",
    "\n",
    "key_cat=pd.read_sql_query(query, conn[1])\n",
    "\n",
    "\n",
    "key_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc826b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keywords in keyword_cat table: set()\n",
      "No of keyword missing 0\n",
      "Run Next cell....\n"
     ]
    }
   ],
   "source": [
    "keycat_list=list(key_cat['keyword'].unique())\n",
    "\n",
    "#keycat_list\n",
    "\n",
    "l1_l2=(set(keystone_key).difference(keycat_list))\n",
    "\n",
    "print(\"Missing keywords in keyword_cat table:\", l1_l2)\n",
    "print('No of keyword missing',len(l1_l2))\n",
    "\n",
    "\n",
    "remaining_keywords=(list(l1_l2)+list(l1_l2))\n",
    "remaining_keywords=[x.replace(\"\\'\",'\"') for x in remaining_keywords]\n",
    "\n",
    "if len(remaining_keywords)>0:\n",
    "    query = f\"\"\" \n",
    "    Select *\n",
    "    from entity.country_channel_keyword_search_volume\n",
    "    where keyword in {tuple(remaining_keywords)} and country_code='{country_id}'\n",
    "    \"\"\"\n",
    "\n",
    "    key_vol=pd.read_sql_query(query, conn[1])\n",
    "    if len(key_vol)>0:\n",
    "        print(key_vol)\n",
    "    else:\n",
    "        print(\"\\nThese keywords are not uploaded in table.\\nPlease verify the reason for not uploading of these keywords\")\n",
    "\n",
    "print('Run Next cell....')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebd5c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to reporting_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to Reporting_Data \n",
      "\n",
      "Check 2:\n",
      "Missing keywords in reporting_data : {'sabritas mini pack', 'sabritas grandes', 'papas fritas limon', 'chips fuego', 'nachos', 'sabritas bbq', 'papas fritas miguelito', 'chips jalapeÃ±o', 'paketaxo', 'sabritas originales', 'chetos mix', 'sabritas flamin hot', 'generico sabritas mini', 'sabritas original', 'flaming hot', 'chetos', 'sabritas naturales', 'rancheritos'}\n",
      "No of keywords: 18\n",
      "\n",
      "Run the next cell\n"
     ]
    }
   ],
   "source": [
    "print('Connecting to reporting_data....')        \n",
    "query = f\"\"\"\n",
    "select *\n",
    "from {tablename}\n",
    "where pipeline_id in {pipe_list} \n",
    "\n",
    "\"\"\"\n",
    "reporting_data = pd.read_sql_query(query, conn2[1])\n",
    "reporting_data['brand_name']=reporting_data['brand_name'].str.title().str.strip()\n",
    "\n",
    "\n",
    "print('connected to Reporting_Data ')\n",
    "key_reporting=reporting_data['keyword'].unique()\n",
    "\n",
    "keycat_list_lower=[item.lower() for item in keycat_list]  #to lower case keycat_list\n",
    "\n",
    "diff2=set(keycat_list_lower).difference(key_reporting)\n",
    "if len(diff2)==0:\n",
    "    print('Data for all keywords present in keyword_category table is present in reporting_Data')\n",
    "else:\n",
    "    print('\\nCheck 2:\\nMissing keywords in reporting_data :',set(keycat_list_lower).difference(key_reporting))\n",
    "    print('No of keywords:',len(set(keycat_list_lower).difference(key_reporting)))\n",
    "\n",
    "print('\\nRun the next cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "810a47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pipe=['641a9269aa486100af363385','64169de6aa486100af354bbf','64169de6aa486100af354b6c','6417ef67aa486100af3587c4']\n",
    "\n",
    "#kwds1=['attachments','accessories','professional','ice cream market']\n",
    "\n",
    "#reporting_data1=reporting_data[~reporting_data['pipeline_id'].isin(pipe)]#!='640808477af12e021d6e00f1']\n",
    "\n",
    "#reporting_data2=reporting_data1[~reporting_data1['keyword'].isin(kwds1)]#!='63fecdc72b8e105f0c3e65cf']\n",
    "\n",
    "#reporting_data3=reporting_data2[reporting_data1['pipeline_id']!='powertrain']\n",
    "# reporting_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a887327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reporting_data=reporting_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c8d05fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\visha\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:73: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>serp_data_keyword</th>\n",
       "      <th>serp_details_keyword</th>\n",
       "      <th>diffrence</th>\n",
       "      <th>MISSING KEYWORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-18</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  crawl_date  serp_data_keyword  serp_details_keyword  diffrence  \\\n",
       "0 2023-03-17                 48                    48          0   \n",
       "1 2023-03-18                 54                    54          0   \n",
       "2 2023-03-19                 54                    54          0   \n",
       "3 2023-03-20                 62                    62          0   \n",
       "4 2023-03-21                 62                    62          0   \n",
       "5 2023-03-22                 52                    52          0   \n",
       "6 2023-03-23                  0                     0          0   \n",
       "\n",
       "  MISSING KEYWORD  \n",
       "0              {}  \n",
       "1              {}  \n",
       "2              {}  \n",
       "3              {}  \n",
       "4              {}  \n",
       "5              {}  \n",
       "6              {}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dates=data['crawl_date'].sort_values().reset_index().drop('index',axis=1)\n",
    "\n",
    "df_dates['serp_data_keyword']=df_dates.apply(lambda x: len(reporting_data[reporting_data['crawl_date']==x.crawl_date].keyword.unique()), axis=1 )\n",
    "\n",
    "\n",
    "\n",
    "serp_data.columns=[*serp_data.columns[:-1],'nitin']\n",
    "\n",
    "df_dates['serp_details_keyword']=df_dates.apply(lambda x: len(serp_data[serp_data['crawl_date']==x.crawl_date].keyword.unique()), axis=1 )\n",
    "\n",
    "df_dates['diffrence']=df_dates['serp_details_keyword']-df_dates['serp_data_keyword']\n",
    "df_dates['MISSING KEYWORD']=df_dates.apply(lambda x: (set(list(serp_data[serp_data['crawl_date']==x.crawl_date].keyword.unique()))).difference(set(list(reporting_data[reporting_data['crawl_date']==x.crawl_date].keyword.unique()))), axis=1 )\n",
    "df_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bffaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dates.to_excel(\"check.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a2e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fecebb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reporting_data=pd.read_excel(r\"382 serp data amazon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f5bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dates.to_excel('vsdvdsv.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead27061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09760a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the Primary Brand----\n",
      "sabritas\n",
      "Following are the crawl dates present in serp_Data\n",
      " [datetime.date(2023, 3, 22) datetime.date(2023, 3, 20)\n",
      " datetime.date(2023, 3, 21) datetime.date(2023, 3, 17)\n",
      " datetime.date(2023, 3, 18) datetime.date(2023, 3, 19)]\n",
      "Enter the Brand name present in reporting data : sabritas\n",
      "['sabritas']\n",
      "\n",
      "List of Brands: ['Sabritas', 'Barcel', 'Great  Value', \"Nature'S Garden\", 'Papabrozas', 'Churrumais', 'Chips', 'Great Value', 'Doritos', 'Bokados', 'Mister', 'Bel Ara', 'Extra Special', 'JosÃ© Cuervo', 'Sabritones', 'Quesabritas', 'Botanas LovieÂ´S', 'Snackatelas', 'Lala', 'San Marcos', 'Provi', 'Mc Cain', 'MÃ©xico Lindo', 'Vegetalistos', 'Pringles', 'Nopalia', 'Marketside', 'CuÃ©tara', 'Tyson', 'Paketaxo', 'Cinta De Oro', 'Parma', 'Zwanenberg', 'Tangamanga', 'Bernina', \"Wand'S\", 'Saladino', 'Paper Craft', 'Kettle', 'Milky Way', 'MacÂ´Ma', 'SonricÂ´S', 'Vero', 'Ferrero Collection', 'Veggie Mix', 'Way To Celebrate', 'TÃ­o Nacho', \"Pilgrim'S\", 'Tio Nacho', 'Bachoco', 'Burr', 'San Ignacio', 'Clemente Jacques', 'La CosteÃ±a', 'El Mexicano', 'Papatinas', 'Tasu', 'Chipotles', 'Takis', 'Hot Nuts', 'Susalia', 'La Morena', 'StoufferÂ´S', 'Brew City', 'Ruffles', 'Cheffry', 'Cheetos', 'Barkys', 'Slim Pop', \"Cashita'S\", 'Prichos', 'Picard', 'Las Sevillanas', 'Ferrero', \"Hershey'S\", 'Charricos', 'Cazares', 'Chen', 'Kowi', 'Kraft', \"Nature'S Heart\", 'Capistrano', 'Voit', 'Cham', 'Aurrera', 'Editorial Epoca', 'San Blas', 'Gamesa', 'Vr Editoras', 'Tusquets', 'Planeta Mexicana', 'Editorial Ãxodo', 'Xbox 360', 'Jorge IbargÃ¼engoitia', 'Boris PlÃ¡stica', 'Krusteaz', 'Fun Kids', 'Mundo Light', 'Norma', \"Nature'S Own\", 'Benavento', 'Hometrends', 'Mega LimÃ³n', 'La Pastora', 'PragnÃ¡', 'SassÃ³n', 'Doblett', 'TajÃ­n', 'Barritas', 'Chips Ahoy!', 'Libanius', 'Marinela', 'Kacang', 'Zwan', 'Casillero Del Diablo', 'Lisa Maxwell', 'Nissin', 'OcÃ©ano', 'Diablo', 'Ranch Style', 'Tres Estrellas', 'Maravillas', 'Oreo', 'Rancho Grande', 'San Miguel', 'Badia', 'Fresh Gourmet', \"Marie'S\", 'La Sierra', 'Zaaschila', 'DondÃ©', 'Mccain', 'Global Premier', 'Barloz', \"Driscoll'S\", 'Disney', 'Mainstays', 'Campo Vivo', 'Regina', 'Wapas', 'Cape Cod', 'Encanto', 'La Guacamaya', 'La Perrona', 'El Yucateco', 'Cholula', 'Amor', 'Yaya', 'De Boca En Boca', 'BÃºfalo', 'La Botanera', 'De La Viuda', 'Paki', 'Tabasco', 'El Diablito', 'Mccormick', 'Campbells', \"Snap'D\", 'Mister Alimentos', 'Mix OÂ´Clock', 'Celebrate', 'Jose Cuervo', 'Dul Cerel', 'Splenda', 'Pinol', 'FolicurÃ©', 'Black & White', 'Clarasol', 'Disaronno', 'V8', 'Escosa', 'DoÃ±a MarÃ­a', 'Lol-Tun', 'Boadas 1880', 'Noel', 'Argal', 'Cumbres Mayores', 'Real IbÃ©rico', 'Pelon Pelo Rico', 'Balmoro', 'Skwinkles', 'Skwinklote', \"Sonric'S\", 'El Sol', 'Miguelito', 'Nipon', 'Calidad Selecta', 'Gabi', 'Turbana', 'Isla Blanca', 'I Am (Aranth)', 'Gerber', 'Oster', 'Tuck', 'Presto', 'Wrigleys', 'Snickers']\n",
      "INPUT BRAND WHICH IS PRESENT IN KEYWORD_CAT TABLE IN A LISTED FORMAT ONLY. with '|'. \n",
      " example : puma|nike|shiv naresh : sabritas\n",
      "\n",
      "List of Brands: ['Sabritas', 'Barcel', 'Great  Value', \"Nature'S Garden\", 'Papabrozas', 'Churrumais', 'Chips', 'Great Value', 'Doritos', 'Bokados', 'Mister', 'Bel Ara', 'Extra Special', 'JosÃ© Cuervo', 'Sabritones', 'Quesabritas', 'Botanas LovieÂ´S', 'Snackatelas', 'Lala', 'San Marcos', 'Provi', 'Mc Cain', 'MÃ©xico Lindo', 'Vegetalistos', 'Pringles', 'Nopalia', 'Marketside', 'CuÃ©tara', 'Tyson', 'Paketaxo', 'Cinta De Oro', 'Parma', 'Zwanenberg', 'Tangamanga', 'Bernina', \"Wand'S\", 'Saladino', 'Paper Craft', 'Kettle', 'Milky Way', 'MacÂ´Ma', 'SonricÂ´S', 'Vero', 'Ferrero Collection', 'Veggie Mix', 'Way To Celebrate', 'TÃ­o Nacho', \"Pilgrim'S\", 'Tio Nacho', 'Bachoco', 'Burr', 'San Ignacio', 'Clemente Jacques', 'La CosteÃ±a', 'El Mexicano', 'Papatinas', 'Tasu', 'Chipotles', 'Takis', 'Hot Nuts', 'Susalia', 'La Morena', 'StoufferÂ´S', 'Brew City', 'Ruffles', 'Cheffry', 'Cheetos', 'Barkys', 'Slim Pop', \"Cashita'S\", 'Prichos', 'Picard', 'Las Sevillanas', 'Ferrero', \"Hershey'S\", 'Charricos', 'Cazares', 'Chen', 'Kowi', 'Kraft', \"Nature'S Heart\", 'Capistrano', 'Voit', 'Cham', 'Aurrera', 'Editorial Epoca', 'San Blas', 'Gamesa', 'Vr Editoras', 'Tusquets', 'Planeta Mexicana', 'Editorial Ãxodo', 'Xbox 360', 'Jorge IbargÃ¼engoitia', 'Boris PlÃ¡stica', 'Krusteaz', 'Fun Kids', 'Mundo Light', 'Norma', \"Nature'S Own\", 'Benavento', 'Hometrends', 'Mega LimÃ³n', 'La Pastora', 'PragnÃ¡', 'SassÃ³n', 'Doblett', 'TajÃ­n', 'Barritas', 'Chips Ahoy!', 'Libanius', 'Marinela', 'Kacang', 'Zwan', 'Casillero Del Diablo', 'Lisa Maxwell', 'Nissin', 'OcÃ©ano', 'Diablo', 'Ranch Style', 'Tres Estrellas', 'Maravillas', 'Oreo', 'Rancho Grande', 'San Miguel', 'Badia', 'Fresh Gourmet', \"Marie'S\", 'La Sierra', 'Zaaschila', 'DondÃ©', 'Mccain', 'Global Premier', 'Barloz', \"Driscoll'S\", 'Disney', 'Mainstays', 'Campo Vivo', 'Regina', 'Wapas', 'Cape Cod', 'Encanto', 'La Guacamaya', 'La Perrona', 'El Yucateco', 'Cholula', 'Amor', 'Yaya', 'De Boca En Boca', 'BÃºfalo', 'La Botanera', 'De La Viuda', 'Paki', 'Tabasco', 'El Diablito', 'Mccormick', 'Campbells', \"Snap'D\", 'Mister Alimentos', 'Mix OÂ´Clock', 'Celebrate', 'Jose Cuervo', 'Dul Cerel', 'Splenda', 'Pinol', 'FolicurÃ©', 'Black & White', 'Clarasol', 'Disaronno', 'V8', 'Escosa', 'DoÃ±a MarÃ­a', 'Lol-Tun', 'Boadas 1880', 'Noel', 'Argal', 'Cumbres Mayores', 'Real IbÃ©rico', 'Pelon Pelo Rico', 'Balmoro', 'Skwinkles', 'Skwinklote', \"Sonric'S\", 'El Sol', 'Miguelito', 'Nipon', 'Calidad Selecta', 'Gabi', 'Turbana', 'Isla Blanca', 'I Am (Aranth)', 'Gerber', 'Oster', 'Tuck', 'Presto', 'Wrigleys', 'Snickers']\n",
      "INPUT BRAND WHICH IS PRESENT IN KEYWORD_CAT TABLE IN A LISTED FORMAT ONLY. with '|'. \n",
      " example : puma|nike|shiv naresh : sabritas\n",
      "\n",
      "List of Brands: ['Sabritas', 'Barcel', 'Great  Value', \"Nature'S Garden\", 'Papabrozas', 'Churrumais', 'Chips', 'Great Value', 'Doritos', 'Bokados', 'Mister', 'Bel Ara', 'Extra Special', 'JosÃ© Cuervo', 'Sabritones', 'Quesabritas', 'Botanas LovieÂ´S', 'Snackatelas', 'Lala', 'San Marcos', 'Provi', 'Mc Cain', 'MÃ©xico Lindo', 'Vegetalistos', 'Pringles', 'Nopalia', 'Marketside', 'CuÃ©tara', 'Tyson', 'Paketaxo', 'Cinta De Oro', 'Parma', 'Zwanenberg', 'Tangamanga', 'Bernina', \"Wand'S\", 'Saladino', 'Paper Craft', 'Kettle', 'Milky Way', 'MacÂ´Ma', 'SonricÂ´S', 'Vero', 'Ferrero Collection', 'Veggie Mix', 'Way To Celebrate', 'TÃ­o Nacho', \"Pilgrim'S\", 'Tio Nacho', 'Bachoco', 'Burr', 'San Ignacio', 'Clemente Jacques', 'La CosteÃ±a', 'El Mexicano', 'Papatinas', 'Tasu', 'Chipotles', 'Takis', 'Hot Nuts', 'Susalia', 'La Morena', 'StoufferÂ´S', 'Brew City', 'Ruffles', 'Cheffry', 'Cheetos', 'Barkys', 'Slim Pop', \"Cashita'S\", 'Prichos', 'Picard', 'Las Sevillanas', 'Ferrero', \"Hershey'S\", 'Charricos', 'Cazares', 'Chen', 'Kowi', 'Kraft', \"Nature'S Heart\", 'Capistrano', 'Voit', 'Cham', 'Aurrera', 'Editorial Epoca', 'San Blas', 'Gamesa', 'Vr Editoras', 'Tusquets', 'Planeta Mexicana', 'Editorial Ãxodo', 'Xbox 360', 'Jorge IbargÃ¼engoitia', 'Boris PlÃ¡stica', 'Krusteaz', 'Fun Kids', 'Mundo Light', 'Norma', \"Nature'S Own\", 'Benavento', 'Hometrends', 'Mega LimÃ³n', 'La Pastora', 'PragnÃ¡', 'SassÃ³n', 'Doblett', 'TajÃ­n', 'Barritas', 'Chips Ahoy!', 'Libanius', 'Marinela', 'Kacang', 'Zwan', 'Casillero Del Diablo', 'Lisa Maxwell', 'Nissin', 'OcÃ©ano', 'Diablo', 'Ranch Style', 'Tres Estrellas', 'Maravillas', 'Oreo', 'Rancho Grande', 'San Miguel', 'Badia', 'Fresh Gourmet', \"Marie'S\", 'La Sierra', 'Zaaschila', 'DondÃ©', 'Mccain', 'Global Premier', 'Barloz', \"Driscoll'S\", 'Disney', 'Mainstays', 'Campo Vivo', 'Regina', 'Wapas', 'Cape Cod', 'Encanto', 'La Guacamaya', 'La Perrona', 'El Yucateco', 'Cholula', 'Amor', 'Yaya', 'De Boca En Boca', 'BÃºfalo', 'La Botanera', 'De La Viuda', 'Paki', 'Tabasco', 'El Diablito', 'Mccormick', 'Campbells', \"Snap'D\", 'Mister Alimentos', 'Mix OÂ´Clock', 'Celebrate', 'Jose Cuervo', 'Dul Cerel', 'Splenda', 'Pinol', 'FolicurÃ©', 'Black & White', 'Clarasol', 'Disaronno', 'V8', 'Escosa', 'DoÃ±a MarÃ­a', 'Lol-Tun', 'Boadas 1880', 'Noel', 'Argal', 'Cumbres Mayores', 'Real IbÃ©rico', 'Pelon Pelo Rico', 'Balmoro', 'Skwinkles', 'Skwinklote', \"Sonric'S\", 'El Sol', 'Miguelito', 'Nipon', 'Calidad Selecta', 'Gabi', 'Turbana', 'Isla Blanca', 'I Am (Aranth)', 'Gerber', 'Oster', 'Tuck', 'Presto', 'Wrigleys', 'Snickers']\n",
      "INPUT BRAND WHICH IS PRESENT IN KEYWORD_CAT TABLE IN A LISTED FORMAT ONLY. with '|'. \n",
      " example : puma|nike|shiv naresh : Sabritas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\AppData\\Local\\Temp\\ipykernel_6004\\2025656891.py:106: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result_13=sov_df_top20[sov_df_top20['brand_name'].isin(BRANDindata)]['sum_sv'].sum() / sov_df_top20['sum_sv'].sum()*100\n",
      "C:\\Users\\visha\\AppData\\Local\\Temp\\ipykernel_6004\\2025656891.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  brand_asin.drop_duplicates('channel_sku_id', inplace= True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crawl for child ASINS.\n",
      " Press 1, else press any key.\n",
      "hhhh\n",
      "Done\n",
      "Run the next cell.\n"
     ]
    }
   ],
   "source": [
    "BRAND=input('\\nEnter the Primary Brand----\\n')\n",
    "allbrand=list(key_cat['brand'].unique())\n",
    "allbrand.sort()\n",
    "\n",
    "while BRAND not in allbrand:\n",
    "    print('\\nList of Brands:',allbrand)\n",
    "    BRAND=input('INPUT BRAND WHICH IS PRESENT IN KEYWORD_CAT TABLE IN A LISTED FORMAT ONLY.')\n",
    "    \n",
    "    \n",
    "#forecasting sheet\n",
    "\n",
    "\n",
    "serp_df=reporting_data\n",
    "unique_sku_df=reporting_data[['channel_sku_id','sku_title','brand_name']].drop_duplicates('channel_sku_id') #unique sku with title for QC purpose\n",
    "days=len(reporting_data['crawl_date'].unique()) #crawling days\n",
    "#\n",
    "print('Following are the crawl dates present in serp_Data\\n',reporting_data['crawl_date'].unique())\n",
    "\n",
    "#1 Competition width\n",
    "a=len(serp_df['brand_name'].unique())\n",
    "a1=serp_df['brand_name'].value_counts()\n",
    "\n",
    "#2\n",
    "#top80 % sov\n",
    "sov_all=serp_df\n",
    "sov_df2=(sov_all.groupby(['brand_name']).crawl_sv.sum().reset_index(name='sum_sv'))\n",
    "sov_df2=sov_df2.sort_values('sum_sv', ascending= False)\n",
    "\n",
    "sov_df2['Label']=np.where(sov_df2['sum_sv'].cumsum()<=sov_df2['sum_sv'].sum() * 0.8,0,1)\n",
    "df_80sku_all=sov_df2[sov_df2['Label']==0]\n",
    "allintensity=df_80sku_all['brand_name'].value_counts().reset_index()\n",
    "allsi=len(allintensity)-1\n",
    "\n",
    "\n",
    "\n",
    "#3 top 500 asins for product job\n",
    "sov_organic=serp_df[serp_df['sponsored']!=1]\n",
    "\n",
    "sov_df1=(sov_organic.groupby(['channel_sku_id']).crawl_sv.sum().reset_index(name='sum_sv'))\n",
    "sov_df1=sov_df1.sort_values('sum_sv', ascending= False)\n",
    "sov_df_final=pd.merge(sov_df1,sov_organic[['channel_sku_id','brand_name','sku_title']], on=['channel_sku_id'], how='left')\n",
    "sov_df_final.drop_duplicates(inplace=True)\n",
    "sov_df_final.to_excel('Top_ASIN.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "#4 top80 % organic\n",
    "sov_df=(sov_organic.groupby(['brand_name']).crawl_sv.sum().reset_index(name='sum_sv'))\n",
    "sov_df=sov_df.sort_values('sum_sv', ascending= False)\n",
    "sov_df['Label']=np.where(sov_df['sum_sv'].cumsum()<=sov_df['sum_sv'].sum() * 0.8,0,1)\n",
    "df_80sku=sov_df[sov_df['Label']==0]\n",
    "competition= len(df_80sku['brand_name'].unique())\n",
    "ocintensity=df_80sku['brand_name'].value_counts().reset_index()\n",
    "oci=len(ocintensity)\n",
    "\n",
    "\n",
    "\n",
    "#5\n",
    "#top80 % sponsered\n",
    "sov_spon=serp_df[serp_df['sponsored']==1]\n",
    "sov_df1=(sov_spon.groupby(['brand_name']).crawl_sv.sum().reset_index(name='sum_sv'))\n",
    "sov_df1=sov_df1.sort_values('sum_sv', ascending= False)\n",
    "\n",
    "sov_df1['Label']=np.where(sov_df1['sum_sv'].cumsum()<=sov_df1['sum_sv'].sum() * 0.8,0,1)\n",
    "df_80sku_spon=sov_df1[sov_df1['Label']==0]\n",
    "osintensity=df_80sku_spon['brand_name'].value_counts().reset_index()\n",
    "#osintensity=osintensity[osintensity['brand_name']>=1]\n",
    "osi=len(osintensity)\n",
    "\n",
    "\n",
    "#10 Brand Keywords hacking\n",
    "b_keyword=key_cat[key_cat['brand']==BRAND]\n",
    "df1=pd.merge(sov_spon[['sku_title','brand_name','keyword']],b_keyword[['keyword','brand']], on=['keyword'], how= 'right')\n",
    "b=len(df1['brand_name'].unique())\n",
    "\n",
    "#input brand for serp_data\n",
    "BRANDindata=[item for item in input(\"Enter the Brand name present in reporting data : \").split('|')]\n",
    "\n",
    "allbrand1=list(serp_df['brand_name'].unique())\n",
    "allbrand1= list(filter(None, allbrand1))\n",
    "#allbrand1.sort()\n",
    "print(BRANDindata)\n",
    "while (set(BRANDindata).issubset(set(allbrand1)))==False:\n",
    "    print('\\nList of Brands:',allbrand1)\n",
    "    BRANDindata=[item for item in input(\"INPUT BRAND WHICH IS PRESENT IN KEYWORD_CAT TABLE IN A LISTED FORMAT ONLY. with '|'. \\n example : puma|nike|shiv naresh : \").split('|')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#12\n",
    "sov_organic_top20=serp_df[(serp_df['organic_rank']<=20) & (serp_df['sponsored']!=1)]\n",
    "sov_organic_top20['brand_name'] = sov_organic_top20['brand_name'].fillna('others')\n",
    "sov_organic_df_top20=(sov_organic_top20.groupby(['brand_name']).crawl_sv.sum().reset_index(name='sum_sv'))\n",
    "sov_organic_df_top20=sov_organic_df_top20.sort_values('sum_sv', ascending= False)\n",
    "try:\n",
    "    result_12=sov_organic_df_top20[sov_organic_df_top20['brand_name'].isin(BRANDindata)]['sum_sv'].sum() / sov_organic_df_top20['sum_sv'].sum()*100\n",
    "except:\n",
    "    result_12=0\n",
    "    \n",
    "#13 \n",
    "sov_sponsored_top20=serp_df[(serp_df['sponsored_rank']<=20) & (serp_df['sponsored']==1)]\n",
    "sov_sponsored_top20['brand_name'] = sov_sponsored_top20['brand_name'].fillna('others')\n",
    "sov_df_top20=(sov_sponsored_top20.groupby(['brand_name']).crawl_sv.sum().reset_index(name='sum_sv'))\n",
    "sov_df_top20=sov_df_top20.sort_values('sum_sv', ascending= False)\n",
    "try:\n",
    "    result_13=sov_df_top20[sov_df_top20['brand_name'].isin(BRANDindata)]['sum_sv'].sum() / sov_df_top20['sum_sv'].sum()*100\n",
    "except:\n",
    "    result_13=0\n",
    "\n",
    "#15,16,17\n",
    "# brand asins\n",
    "brand_asin=serp_df[serp_df['brand_name'].isin(BRANDindata)]\n",
    "brand_asin.groupby('channel_sku_id')['rating_count'].max()\n",
    "brand_asin.drop_duplicates('channel_sku_id', inplace= True)\n",
    "\n",
    "#16 \n",
    "avg_brand_rating=brand_asin['rating'].mean()\n",
    "avg_brand_rating\n",
    "\n",
    "#\n",
    "ratings_df=serp_df[['channel_sku_id','sku_title','brand_name','rating','rating_count','crawl_date']]\n",
    "max_count=ratings_df.groupby(['channel_sku_id','brand_name'])['rating_count'].max().reset_index()\n",
    "min_count=ratings_df.groupby(['channel_sku_id','brand_name'])['rating_count'].min().reset_index()\n",
    "\n",
    "#15 Reviews average # per ASIN\n",
    "\n",
    "pr_brand=max_count[max_count['brand_name'].isin(BRANDindata)].sort_values('rating_count', ascending= False)\n",
    "pr_brand.dropna(inplace= True)\n",
    "pr1_brand=pd.merge(pr_brand,unique_sku_df, on=['channel_sku_id'], how='left')\n",
    "\n",
    "Reviews_average_per_ASIN=pr_brand['rating_count'].sum()\n",
    "\n",
    "\n",
    "\n",
    "# DIFF OF REVIEWS MAX-MIN\n",
    "dif_review=pd.merge(min_count,max_count, on=['channel_sku_id'], how= 'outer')\n",
    "dif_review=dif_review.fillna(0)\n",
    "dif_review['change_in_rating']=dif_review['rating_count_y']-dif_review['rating_count_x']\n",
    "\n",
    "#17 New reviews # in last 30 days (on top ASINS)\n",
    "\n",
    "\n",
    "p_brand=dif_review[(dif_review['change_in_rating']!=0) & (dif_review['brand_name_x'].isin(BRANDindata))].sort_values('change_in_rating', ascending= False)\n",
    "p1_brand=pd.merge(p_brand,unique_sku_df, on=['channel_sku_id'], how='left')\n",
    "\n",
    "sumr=p_brand['change_in_rating'].sum()\n",
    "\n",
    "#19 Price Range\n",
    "uniquesku=serp_df[['channel_sku_id','sku_title','price','brand_name']].drop_duplicates('channel_sku_id')\n",
    "nonbrand_asin=uniquesku[~uniquesku['brand_name'].isin(BRANDindata)]\n",
    "branded_asin=uniquesku[uniquesku['brand_name'].isin(BRANDindata)]\n",
    "\n",
    "avg_brand_price=branded_asin['price'].mean()\n",
    "avg_nonbrand_price=nonbrand_asin['price'].mean()\n",
    "price_range=(avg_brand_price-avg_nonbrand_price)/avg_nonbrand_price*100\n",
    "\n",
    "# #20\n",
    "# #best seller \n",
    "\n",
    "# client_cat=key_cat[['category','sub_category']].drop_duplicates()\n",
    "# cct=(list(client_cat['sub_category']))\n",
    "# cct+=cct\n",
    "# cct=tuple(cct)\n",
    "# query=f\"\"\"\n",
    "# select *\n",
    "# from client_resource.client_category_subcategory\n",
    "# where client_id ='{client_id}' and sub_category in {cct} \n",
    "# \"\"\"\n",
    "# c_cat_subcat=pd.read_sql_query(query, conn[1])\n",
    "# mc_cat_id=list(c_cat_subcat['mc_category_id'])\n",
    "# mc_cat_id+=mc_cat_id\n",
    "# mc_cat_id=tuple(mc_cat_id)\n",
    "\n",
    "# query=f\"\"\"\n",
    "# select *\n",
    "# from ready.ready_product\n",
    "# where client_id ='{client_id}' \n",
    "# and category_id in {mc_cat_id}\n",
    "# and crawl_date > now() - interval '3 day '\n",
    "# \"\"\"\n",
    "\n",
    "# ready_product_data=pd.read_sql_query(query, conn[1])\n",
    "# ready_product_data=ready_product_data.sort_values(['category_id','rank']).reset_index().drop('index',axis=1)\n",
    "\n",
    "# recent_date=ready_product_data['crawl_date'].max()\n",
    "# rpd1=ready_product_data[(ready_product_data['crawl_date']==recent_date) & (ready_product_data['rank']<=100)][['category','category_id','asin','title','rank']]\n",
    "\n",
    "#21\n",
    "\n",
    "crawl_input=input('Do you want to crawl for child ASINS.\\n Press 1, else press any key.\\n')\n",
    "if crawl_input=='1':\n",
    "    # #21 Product range depth\n",
    "    url=input('For Child ASINS.\\nEnter country-specific TLDâs: for amazon homepagelink.\\nexample: \\nfor netherland Type---- nl\\nfor usa Type---- com \\nfor INDIA Type---- in\\nfor australia Type--- com.au\\n\\nwww.amazon.')\n",
    "    top30_product=sov_df_final[sov_df_final['brand_name'].isin(BRANDindata)].drop_duplicates('channel_sku_id').head(30)\n",
    "    top30_product.reset_index(drop= True,inplace= True)\n",
    "    top30_product['child_asin']=top30_product.apply(lambda x: child_asin_count(url,x.channel_sku_id), axis=1)\n",
    "    \n",
    "    child=top30_product.replace(0,1)\n",
    "    product_depth_range=child['child_asin'].sum()/len(child)\n",
    "    \n",
    "    child1=pd.merge(child,unique_sku_df, on=['channel_sku_id'], how='left')\n",
    "else:\n",
    "    top30_product=pd.DataFrame([[\"no crawling Done\"]],columns = ['Index'])\n",
    "    product_depth_range=\"\"\n",
    "    child1=top30_product\n",
    "    \n",
    "    #child1=pd.merge(child,unique_sku_df, on=['channel_sku_id'], how='left')\n",
    "\n",
    "#forecasting sheet\n",
    "forecasting=[['1','Competition width','How many brands are selling products in the brandâs category?',a-1],\n",
    "             ['2','Fragmented/Concentrated competition','How many renowned competitors are appearing in the top 80% SOV',allsi],\n",
    "             ['3','Number of 3rd party sellers','How many 3rd party sellers are selling products in the category?',''],\n",
    "             ['4','Organic Competition intensity','How many competitorsâ brands achieve a high visbility in the top organic results?',oci],\n",
    "             ['5','Paid Competition intensity','How many competitorsâ brands achieve a high visbility in the top paid results?',osi],\n",
    "             ['6','Paid entry cost Marketplace, GENERIC','Average recommended minimum CPCÂ ?',''],\n",
    "             ['7','Buy box win rate','What is your brandâs Buy box win rate in %',''],\n",
    "             ['8','Average AUTHORIZED #sellers selling our brand','What is the number of 3rd party sellers selling the brandâs products',''],\n",
    "             ['9','Average UNAUTHORIZED #sellers selling our brand','How many non official sellers are selling your brand and products',''],\n",
    "             ['10','Brand Keywords hackingÂ ','How many brands bid on your brand name',b],\n",
    "             ['11','Brandâs Product Detailed Page hacking','Are some Brandâs Product detailed Pages hacked by competitors or sellers',''],\n",
    "             ['12','Organic share of shelves Marketplace','',result_12],\n",
    "             ['13','Paid share of shelves Marketplace','',result_13],\n",
    "             ['14','Images & text quality','What is the quality of text and images of the brandâs Product Detailed Page',''],\n",
    "             ['15','Reviews average # per ASIN','What is the brandâs number of reviews per asin in average',round(Reviews_average_per_ASIN,0)],\n",
    "             ['16','Reviews average rating score','What is the brandâs review average rating score',round(avg_brand_rating,2)],\n",
    "             ['17','New reviews # in last {} days (on top ASINS)'.format(days),'How many reviews were posted in the last days in average per asin',round(sumr,0)],\n",
    "             ['18','A+page','What is the Quality of the brandâs A+ pages if any',''],\n",
    "             ['19','Price range','How competitive are your Brandâs prices',price_range],\n",
    "             ['20','Share of best seller rank','How many brandâs SKUs are in the Best sellers',''],\n",
    "             ['21','Product range depth','What is the depth of the brandâs product range sold on the platform',product_depth_range]]\n",
    "final_sheet_fc = pd.DataFrame(forecasting, columns = ['Index','Title', 'Definition','Value'])\n",
    "\n",
    "\n",
    "print('Done\\nRun the next cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a6a57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#to excel file\n",
    "fileout='Forecasting_'+BRAND+\"_\"+country_id+\"_\"+Rno+\"_\"+Channel+'.xlsx'\n",
    "with pd.ExcelWriter(fileout, engine='xlsxwriter')as writer:\n",
    "        final_sheet_fc.to_excel(writer,sheet_name='Forecasting' ,startrow=0,startcol=0,index=False)\n",
    "        sov_df_final.to_excel(writer,sheet_name='top_asins' ,startrow=0,startcol=0,index=False)\n",
    "        \n",
    "        a1.to_excel(writer,sheet_name='1-5' ,startrow=0,startcol=0)\n",
    "        df_80sku_all.to_excel(writer,sheet_name='1-5' ,startrow=0,startcol=3,index=False)\n",
    "        df_80sku.to_excel(writer,sheet_name='1-5' ,startrow=0,startcol=7,index=False)\n",
    "        df_80sku_spon.to_excel(writer,sheet_name='1-5' ,startrow=0,startcol=11,index=False)\n",
    "        df1.to_excel(writer,sheet_name='10' ,startrow=0,startcol=0,index=False)\n",
    "        sov_organic_df_top20[['brand_name','sum_sv']].to_excel(writer,sheet_name='12' ,startrow=0,startcol=0,index=False)\n",
    "        sov_df_top20[['brand_name','sum_sv']].to_excel(writer,sheet_name='13' ,startrow=0,startcol=0,index=False)\n",
    "        pr1_brand.to_excel(writer,sheet_name='15' ,startrow=0,startcol=0,index=False)\n",
    "        brand_asin[['channel_sku_id','sku_title','brand_name','price','mrp','rating','rating_count']].to_excel(writer,sheet_name='16' ,startrow=0,startcol=0,index=False)\n",
    "        p1_brand.to_excel(writer,sheet_name='17' ,startrow=0,startcol=0,index=False)\n",
    "        uniquesku.to_excel(writer,sheet_name='19' ,startrow=0,startcol=0,index=False)\n",
    "        nonbrand_asin.to_excel(writer,sheet_name='19' ,startrow=0,startcol=5,index=False)\n",
    "        branded_asin.to_excel(writer,sheet_name='19' ,startrow=0,startcol=10,index=False)\n",
    "        #rpd1.to_excel(writer,sheet_name='20' ,startrow=0,startcol=0,index=False)\n",
    "        child1.to_excel(writer,sheet_name='21' ,startrow=0,startcol=0,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "488f2f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Competition width</td>\n",
       "      <td>How many brands are selling products in the br...</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fragmented/Concentrated competition</td>\n",
       "      <td>How many renowned competitors are appearing in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Number of 3rd party sellers</td>\n",
       "      <td>How many 3rd party sellers are selling product...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Organic Competition intensity</td>\n",
       "      <td>How many competitorsâ brands achieve a high vi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Paid Competition intensity</td>\n",
       "      <td>How many competitorsâ brands achieve a high vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Paid entry cost Marketplace, GENERIC</td>\n",
       "      <td>Average recommended minimum CPCÂ ?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Buy box win rate</td>\n",
       "      <td>What is your brandâs Buy box win rate in %</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Average AUTHORIZED #sellers selling our brand</td>\n",
       "      <td>What is the number of 3rd party sellers sellin...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Average UNAUTHORIZED #sellers selling our brand</td>\n",
       "      <td>How many non official sellers are selling your...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Brand Keywords hacking</td>\n",
       "      <td>How many brands bid on your brand name</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Brandâs Product Detailed Page hacking</td>\n",
       "      <td>Are some Brandâs Product detailed Pages hacked...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Organic share of shelves Marketplace</td>\n",
       "      <td></td>\n",
       "      <td>58.637714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Paid share of shelves Marketplace</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Images &amp; text quality</td>\n",
       "      <td>What is the quality of text and images of the ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Reviews average # per ASIN</td>\n",
       "      <td>What is the brandâs number of reviews per asin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Reviews average rating score</td>\n",
       "      <td>What is the brandâs review average rating score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>New reviews # in last 6 days (on top ASINS)</td>\n",
       "      <td>How many reviews were posted in the last days ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>A+page</td>\n",
       "      <td>What is the Quality of the brandâs A+ pages if...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Price range</td>\n",
       "      <td>How competitive are your Brandâs prices</td>\n",
       "      <td>-51.332372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Share of best seller rank</td>\n",
       "      <td>How many brandâs SKUs are in the Best sellers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Product range depth</td>\n",
       "      <td>What is the depth of the brandâs product range...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Title  \\\n",
       "0      1                                Competition width   \n",
       "1      2              Fragmented/Concentrated competition   \n",
       "2      3                      Number of 3rd party sellers   \n",
       "3      4                    Organic Competition intensity   \n",
       "4      5                       Paid Competition intensity   \n",
       "5      6             Paid entry cost Marketplace, GENERIC   \n",
       "6      7                                 Buy box win rate   \n",
       "7      8    Average AUTHORIZED #sellers selling our brand   \n",
       "8      9  Average UNAUTHORIZED #sellers selling our brand   \n",
       "9     10                          Brand Keywords hackingÂ    \n",
       "10    11            Brandâs Product Detailed Page hacking   \n",
       "11    12             Organic share of shelves Marketplace   \n",
       "12    13                Paid share of shelves Marketplace   \n",
       "13    14                            Images & text quality   \n",
       "14    15                       Reviews average # per ASIN   \n",
       "15    16                     Reviews average rating score   \n",
       "16    17      New reviews # in last 6 days (on top ASINS)   \n",
       "17    18                                           A+page   \n",
       "18    19                                      Price range   \n",
       "19    20                        Share of best seller rank   \n",
       "20    21                              Product range depth   \n",
       "\n",
       "                                           Definition      Value  \n",
       "0   How many brands are selling products in the br...        197  \n",
       "1   How many renowned competitors are appearing in...          3  \n",
       "2   How many 3rd party sellers are selling product...             \n",
       "3   How many competitorsâ brands achieve a high vi...          4  \n",
       "4   How many competitorsâ brands achieve a high vi...          0  \n",
       "5                   Average recommended minimum CPCÂ ?             \n",
       "6          What is your brandâs Buy box win rate in %             \n",
       "7   What is the number of 3rd party sellers sellin...             \n",
       "8   How many non official sellers are selling your...             \n",
       "9              How many brands bid on your brand name          1  \n",
       "10  Are some Brandâs Product detailed Pages hacked...             \n",
       "11                                                     58.637714  \n",
       "12                                                           NaN  \n",
       "13  What is the quality of text and images of the ...             \n",
       "14  What is the brandâs number of reviews per asin...        0.0  \n",
       "15    What is the brandâs review average rating score        NaN  \n",
       "16  How many reviews were posted in the last days ...        0.0  \n",
       "17  What is the Quality of the brandâs A+ pages if...             \n",
       "18            How competitive are your Brandâs prices -51.332372  \n",
       "19      How many brandâs SKUs are in the Best sellers             \n",
       "20  What is the depth of the brandâs product range...             "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sheet_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dea3d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Crawled for 6 days\n",
      "1. Competition width---------------------------------------------------------- 197\n",
      "2. Fragmented/Concentrated competition --------------------------------------- 3\n",
      "3. Number of 3rd party sellers: ------------- top 500 asins exported for product job.\n",
      "4. Organic Competition intensity---------------------------------------------- 4\n",
      "5. Paid Competition intensity------------------------------------------------- 0\n",
      "6. Paid entry cost Marketplace, GENERIC\n",
      "7. Buy box win rate\n",
      "8. Average AUTHORIZED #sellers selling our brand\n",
      "9. Average UNAUTHORIZED #sellers selling our brand\n",
      "10. Brand Keywords hacking----------------------------------------------------- 1\n",
      "11. Brandâs Product Detailed Page hacking\n",
      "12. Organic share of shelves Marketplace--------------------------------------- 58.63771389018916\n",
      "13. Paid share of shelves Marketplace------------------------------------------ nan\n",
      "14. Images & text quality\n",
      "15. Reviews average # per ASIN------------------------------------------------- 0.0\n",
      "16. Reviews average rating score----------------------------------------------- nan\n",
      "17. New reviews # in last 6 days (on top ASINS)------------------------------- 0.0\n",
      "18. A+page\n",
      "19. Price range----------------------------------------------------------------- -51.33237207424038\n",
      "20. Share of best seller rank\n",
      "21. Product range depth-------------------------------------------------------- \n"
     ]
    }
   ],
   "source": [
    "print('Data Crawled for {} days'.format(days))\n",
    "print('1. Competition width----------------------------------------------------------', a-1)\n",
    "print('2. Fragmented/Concentrated competition ---------------------------------------',allsi)\n",
    "print('3. Number of 3rd party sellers: ------------- top 500 asins exported for product job.')\n",
    "print('4. Organic Competition intensity----------------------------------------------',oci)\n",
    "print('5. Paid Competition intensity-------------------------------------------------',osi)\n",
    "print('6. Paid entry cost Marketplace, GENERIC')\n",
    "print('7. Buy box win rate')\n",
    "print('8. Average AUTHORIZED #sellers selling our brand')\n",
    "print('9. Average UNAUTHORIZED #sellers selling our brand')\n",
    "print('10. Brand Keywords hacking-----------------------------------------------------',b)\n",
    "print('11. Brandâs Product Detailed Page hacking')\n",
    "print('12. Organic share of shelves Marketplace---------------------------------------',result_12)\n",
    "print('13. Paid share of shelves Marketplace------------------------------------------',result_13)\n",
    "print('14. Images & text quality')\n",
    "print('15. Reviews average # per ASIN-------------------------------------------------',round(Reviews_average_per_ASIN,0))\n",
    "print('16. Reviews average rating score-----------------------------------------------',round(avg_brand_rating,2))\n",
    "print('17. New reviews # in last {} days (on top ASINS)-------------------------------'.format(days),round(sumr,0))\n",
    "print('18. A+page')\n",
    "print('19. Price range-----------------------------------------------------------------',price_range)\n",
    "print('20. Share of best seller rank')\n",
    "print('21. Product range depth--------------------------------------------------------',product_depth_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2237ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn[0].close()\n",
    "conn[1].close()\n",
    "conn2[0].close()\n",
    "conn2[1].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501abed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222f2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d40bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_data.to_excel(\"379 serp data tesco.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39683786",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_brand_rating=brand_asin['rating'].mean()\n",
    "avg_brand_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_asin['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35270e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
